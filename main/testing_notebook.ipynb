{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598dca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessor\n",
    "from data_loader import load_json_data\n",
    "from evaluation import compute_f1_scores, per_tag_f1\n",
    "from baseline import tf_idf\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92da9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_tags=['math', 'graphs', 'strings', 'number theory', 'trees', 'geometry', 'games', 'probabilities']\n",
    "path=r\"C:\\Users\\maloc\\OneDrive\\Documents\\Tag Classification\\Code-Tag-Classification\\data\\code_classification_dataset.zip\"\n",
    "data=load_json_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834d2c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHECKING SPLIT BALANCE ===\n",
      "\n",
      "=== Focus Tags Statistics ===\n",
      "math            | train: 1157 dev: 128 test: 124\n",
      "graphs          | train: 435 dev:  54 test:  53\n",
      "strings         | train: 344 dev:  48 test:  30\n",
      "number theory   | train: 285 dev:  31 test:  34\n",
      "trees           | train: 252 dev:  36 test:  36\n",
      "geometry        | train: 131 dev:  17 test:  18\n",
      "games           | train:  82 dev:  11 test:  12\n",
      "probabilities   | train:  73 dev:  12 test:   7\n",
      "TRAIN SIZE: 3985\n",
      "DEV SIZE: 498\n",
      "TEST SIZE: 499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['*special', '2-sat', 'binary search', 'bitmasks', 'brute force', 'chinese remainder theorem', 'combinatorics', 'constructive algorithms', 'data structures', 'dfs and similar', 'divide and conquer', 'dp', 'dsu', 'expression parsing', 'fft', 'flows', 'graph matchings', 'greedy', 'hashing', 'implementation', 'interactive', 'matrices', 'meet-in-the-middle', 'schedules', 'shortest paths', 'sortings', 'string suffix structures', 'ternary search', 'two pointers'] will be ignored\n",
      "  warnings.warn(\n",
      "c:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['*special', '2-sat', 'binary search', 'bitmasks', 'brute force', 'chinese remainder theorem', 'combinatorics', 'constructive algorithms', 'data structures', 'dfs and similar', 'divide and conquer', 'dp', 'dsu', 'expression parsing', 'fft', 'flows', 'graph matchings', 'greedy', 'hashing', 'implementation', 'interactive', 'matrices', 'shortest paths', 'sortings', 'string suffix structures', 'ternary search', 'two pointers'] will be ignored\n",
      "  warnings.warn(\n",
      "c:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['*special', '2-sat', 'binary search', 'bitmasks', 'brute force', 'combinatorics', 'constructive algorithms', 'data structures', 'dfs and similar', 'divide and conquer', 'dp', 'dsu', 'expression parsing', 'fft', 'flows', 'graph matchings', 'greedy', 'hashing', 'implementation', 'interactive', 'matrices', 'shortest paths', 'sortings', 'string suffix structures', 'ternary search', 'two pointers'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessor=Preprocessor(use_code=True,focus_only=True)\n",
    "train_text, dev_text, test_text, train_labels_bin, dev_labels_bin, test_labels_bin=preprocessor.process_data(data,devset=True,test_size=0.2) # type: ignore\n",
    "mlb_classes=preprocessor.label_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7be07",
   "metadata": {},
   "source": [
    "# TF IDF baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06297631",
   "metadata": {},
   "source": [
    "First baseline mdoel is an invese frequency model, the data is whole descriptions or source codes and targets are the corresponding tags, minimal preprocessing is applied (cleaning text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe3136",
   "metadata": {},
   "source": [
    "We see great imbalances in classes, need to tune threshold per classes for best results probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c989f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf=tf_idf(classes=mlb_classes)\n",
    "model_tf.fit(train_text,train_labels_bin)\n",
    "y_true_binary=test_labels_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd441d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('math', 0.55),\n",
       " ('graphs', 0.47),\n",
       " ('strings', 0.63),\n",
       " ('number theory', 0.29),\n",
       " ('trees', 0.66),\n",
       " ('geometry', 0.11),\n",
       " ('games', 0.4),\n",
       " ('probabilities', 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction using base threshold p=0.5\n",
    "\n",
    "y_pred_binary=model_tf.predict(test_text)\n",
    "\n",
    "per_tag_f1(y_true_binary,y_pred_binary,focus_tags=focus_tags,mlb_classes=mlb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53068fc",
   "metadata": {},
   "source": [
    "[('math', 0.44),\n",
    " ('graphs', 0.42),\n",
    " ('strings', 0.63),\n",
    " ('number theory', 0.51),\n",
    " ('trees', 0.64),\n",
    " ('geometry', 0.56),\n",
    " ('games', 0.71),\n",
    " ('probabilities', 0.0)]\n",
    "\n",
    "\n",
    "[('math', 0.53),\n",
    " ('graphs', 0.51),\n",
    " ('strings', 0.48),\n",
    " ('number theory', 0.22),\n",
    " ('trees', 0.54),\n",
    " ('geometry', 0.0),\n",
    " ('games', 0.2),\n",
    " ('probabilities', 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffa868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('math', 0.41),\n",
       " ('graphs', 0.45),\n",
       " ('strings', 0.64),\n",
       " ('number theory', 0.53),\n",
       " ('trees', 0.61),\n",
       " ('geometry', 0.5),\n",
       " ('games', 0.67),\n",
       " ('probabilities', 0.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune threshold globally to get better results, most classes are low count so p=0.5 is quite bad \n",
    "\n",
    "best_thresh,best_f1=model_tf.tune_threshold(dev_text,dev_labels_bin,depth=10)\n",
    "\n",
    "y_pred_binary=model_tf.predict(test_text)\n",
    "per_tag_f1(y_true_binary,y_pred_binary,focus_tags=focus_tags,mlb_classes=mlb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a5c34",
   "metadata": {},
   "source": [
    "[('math', 0.44),\n",
    " ('graphs', 0.42),\n",
    " ('strings', 0.63),\n",
    " ('number theory', 0.51),\n",
    " ('trees', 0.64),\n",
    " ('geometry', 0.56),\n",
    " ('games', 0.71),\n",
    " ('probabilities', 0.0)]\n",
    "\n",
    "[('math', 0.45),\n",
    " ('graphs', 0.58),\n",
    " ('strings', 0.68),\n",
    " ('number theory', 0.48),\n",
    " ('trees', 0.63),\n",
    " ('geometry', 0.36),\n",
    " ('games', 0.48),\n",
    " ('probabilities', 0.0)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b79c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('math', 0.55),\n",
       " ('graphs', 0.53),\n",
       " ('strings', 0.71),\n",
       " ('number theory', 0.57),\n",
       " ('trees', 0.68),\n",
       " ('geometry', 0.5),\n",
       " ('games', 0.73),\n",
       " ('probabilities', 0.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune threshold per class to get best results\n",
    "\n",
    "best_thresholds,best_f1_per_class=model_tf.tune_per_tag_threshold(dev_text,dev_labels_bin,depth=20)\n",
    "y_pred_binary=model_tf.predict(test_text)\n",
    "\n",
    "per_tag_f1(y_true_binary,y_pred_binary,focus_tags=focus_tags,mlb_classes=mlb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f689ce",
   "metadata": {},
   "source": [
    "[('math', 0.55),\n",
    " ('graphs', 0.54),\n",
    " ('strings', 0.63),\n",
    " ('number theory', 0.47),\n",
    " ('trees', 0.62),\n",
    " ('geometry', 0.58),\n",
    " ('games', 0.73),\n",
    " ('probabilities', 0.0)]\n",
    "\n",
    "[('math', 0.55),\n",
    " ('graphs', 0.6),\n",
    " ('strings', 0.63),\n",
    " ('number theory', 0.48),\n",
    " ('trees', 0.65),\n",
    " ('geometry', 0.47),\n",
    " ('games', 0.68),\n",
    " ('probabilities', 0.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb106677",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0292dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import BertPreprocessor\n",
    "from model import CodeBERTClassifier\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MAX_LEN = 512   # truncating at Description+ code at 512 token so losing only code, \n",
    "                # might be better to trunk description and code at 256 because description might be very long\n",
    "BATCH_SIZE = 16 \n",
    "MODEL_NAME = 'microsoft/codebert-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de878e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpreprocessor=BertPreprocessor(tokenizer=tokenizer,max_len=MAX_LEN,batch_size=BATCH_SIZE,use_code=False)\n",
    "train_loader = bpreprocessor.preprocess_data(train_text,train_labels_bin,shuffle=True)\n",
    "dev_loader = bpreprocessor.preprocess_data(dev_text,dev_labels_bin,shuffle=False)\n",
    "test_loader = bpreprocessor.preprocess_data(test_text,test_labels_bin,shuffle=False)\n",
    "\n",
    "pos_weights=bpreprocessor.get_pos_weight(train_labels_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a017cc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé sur cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CodeBERTClassifier(mlb_classes=mlb_classes, model_name=MODEL_NAME)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Modèle chargé sur {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73e8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(train_loader,dev_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m,pos_weight\u001b[38;5;241m=\u001b[39mpos_weights)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtune_thresholds(dev_loader, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Lancement de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mévaluation ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maloc\\OneDrive\\Documents\\Tag Classification\\Code-Tag-Classification\\main\\model.py:38\u001b[0m, in \u001b[0;36mCodeBERTClassifier.fit\u001b[1;34m(self, train_loader, dev_loader, epochs, lr, device, save_path, pos_weight)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mTrain model and save best version\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Optimiseur for transformers AdamW with Weight Decay, more robust to overfitting\u001b[39;00m\n\u001b[0;32m     41\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1371\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 930\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 930\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 930\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:957\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 957\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    958\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1352\u001b[0m             device,\n\u001b[0;32m   1353\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1354\u001b[0m             non_blocking,\n\u001b[0;32m   1355\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1356\u001b[0m         )\n\u001b[1;32m-> 1357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1358\u001b[0m         device,\n\u001b[0;32m   1359\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1360\u001b[0m         non_blocking,\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\maloc\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_loader,dev_loader, epochs=4, lr=2e-5,save_path='best_model.pt',pos_weight=pos_weights)\n",
    "model.tune_thresholds(dev_loader, device='cuda')\n",
    "print(\"\\n--- Lancement de l'évaluation ---\")\n",
    "global_metrics, tag_results = model.evaluate_model(\n",
    "    data_loader=test_loader,  # Utilise ton loader de test ici\n",
    "    device='cuda',\n",
    "    target_tags=focus_tags       # Les tags sur lesquels tu veux le détail\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRésumé F1 Score Global (Micro):\", global_metrics['micro_f1'])\n",
    "print(\"Résumé F1 Score Global (Macro):\", global_metrics['macro_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f68cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
